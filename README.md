# Vera ğŸ¤–

Vera is a **personal-use AI assistant**, designed for **local experimentation** and future evolution into a potential **SaaS product**.

It features:
- Long-term conversation memory (vector store)
- Retrieval-Augmented Generation (RAG)
- Streaming LLM responses via Ollama
- Optional speech-to-text and text-to-speech modules

This repository exposes Vera as an **HTTP API**, allowing usage from:
- Postman
- Web applications (Vue / React)
- Mobile applications (iOS / Android)
- Any internet-connected client

---

## âœ¨ Features

- ğŸ§  **Conversation Memory** â€“ semantic recall of relevant past interactions  
- ğŸ” **RAG Pipeline** â€“ vector search + external context (e.g. Twitch chat)  
- ğŸ’¬ **Chat API** â€“ simple and extensible `/chat` endpoint  
- ğŸ–¥ï¸ **CLI Interface** â€“ legacy local assistant for fast iteration  
- ğŸ—£ï¸ **Speech-to-Text** â€“ Whisper (default), Vosk (offline fallback)  
- ğŸ”Š **Text-to-Speech** â€“ XTTS (disabled by default due to latency)  
- ğŸŒ **Internet Exposure** â€“ free HTTPS access via Cloudflare Tunnel  
- ğŸ” **Optional Authentication** â€“ API keyâ€“based security  

---

## ğŸ—ï¸ Project Structure

```text
.
â”œâ”€â”€ api.py                     # FastAPI entrypoint (HTTP API)
â”œâ”€â”€ vera_core.py               # Core Vera engine (LLM + memory + RAG)
â”œâ”€â”€ vera_cli.py                # Legacy CLI interface for local testing
â”œâ”€â”€ authorization.py           # Optional API key authentication
â”œâ”€â”€ db.py                      # Conversation persistence
â”œâ”€â”€ vector_store.py            # Embeddings + vector database logic
â”œâ”€â”€ query_builder.py           # Query expansion logic
â”œâ”€â”€ external_rag_module.py     # External RAG sources (e.g. Twitch)
â”œâ”€â”€ speech_to_text_whisper.py  # Whisper STT (default)
â”œâ”€â”€ speech_to_text_vosk.py     # Vosk STT (offline fallback)
â”œâ”€â”€ text_to_speech_xtts.py     # XTTS TTS (optional)
â”œâ”€â”€ schema.sql                 # Database schema (table creation)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## âš™ï¸ Requirements

- Python **3.10+**
- Ollama installed and running
- Supported LLM model (e.g. `llama3`)

---

## ğŸ“¦ Installation

Install dependencies:
```bash
pip install -r requirements.txt
```

Ensure Ollama is running:
```bash
ollama serve
```

Pull the model:
```bash
ollama pull llama3
```

## â–¶ï¸ Run the API Locally
```bash
uvicorn api:app --host 0.0.0.0 --port 8000
```

API available at:

http://localhost:8000

Swagger UI:

http://localhost:8000/docs

## Endpoints

### 1. `POST /chat` â€” Text Chat

Send a text message to Vera and receive a response.

**Request Body:**

| Field        | Type   | Required | Description |
|-------------|--------|----------|-------------|
| `session_id` | string | No       | Optional session ID to continue a previous conversation. If omitted, a new session is created. |
| `message`    | string | Yes      | The user message or prompt for Vera. |

**Example Request (JSON):**

```json
{
  "session_id": "abc123",
  "message": "Hello Vera, how are you?"
}
```

**Reponse:**

| Field        | Type   | Required | Description |
|-------------|--------|----------|-------------|
| `session_id` | string | No       | The session ID (useful to continue the conversation). |
| `response`    | string | Yes      | Vera's generated response to the message. |

**Example Response (JSON):**

```json
{
  "session_id": "abc123",
  "response": "Hello! I'm doing great. How can I assist you today?"
}
```

### 2. `POST /transcribe` â€” Audio Transcription

Upload an audio file to transcribe its content into text.

**Request:**

- **Content-Type:** `multipart/form-data`
- **Form Field:**

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `file` | file | Yes | Audio file to transcribe. Supported formats: any audio MIME type. |

**Example (curl):**

```bash
curl -X POST "http://<your-server-address>/transcribe" \
  -H "Authorization: Bearer <YOUR_API_KEY>" \
  -F "file=@audio_sample.webm"
```

| Field | Type  | Description |
|-------|-------|-------------|
| `transcript` | string | Transcribed text from the audio file. |

**Example Response (JSON):**

```json
{
  "transcript": "Hello Vera, can you tell me a fun fact?"
}
```

### 3. `POST /audio` â€” Audio Chat

Upload an audio file and receive both transcription and Vera's response.

**Request:**

- **Content-Type:** `multipart/form-data`
- **Form Fields:**

| Field        | Type   | Required | Description |
|-------------|--------|----------|-------------|
| `file`       | file   | Yes      | Audio file containing the user's speech. |
| `session_id` | string | No       | Optional session ID for conversation continuity. |

**Example (curl):**

```bash
curl -X POST "http://<your-server-address>/audio" \
  -H "Authorization: Bearer <YOUR_API_KEY>" \
  -F "file=@user_speech.webm" \
  -F "session_id=abc123"
  ```

**Response:**

| Field               | Type           | Description |
|--------------------|----------------|-------------|
| `session_id`        | string         | Session ID for conversation continuity. |
| `transcript`        | string         | Transcribed text from the audio. |
| `response`          | string         | Vera's generated response to the transcribed text. |
| `response_audio_url`| string or null | Placeholder for TTS audio URL (currently `null`). |

**Example Response:**

```json
{
  "session_id": "abc123",
  "transcript": "Hello Vera, tell me a joke.",
  "response": "Sure! Why did the computer go to the doctor? Because it caught a virus!",
  "response_audio_url": null
}

## ğŸ–¥ï¸ Run Vera via CLI (Legacy)

Before the API existed, Vera was used as a **local CLI assistant** for rapid testing.

```bash
python vera_cli.py
```

This mode supports:

- Local conversation loop
- Memory recall
- Optional voice input/output

âš ï¸ The CLI is considered **legacy** and intended mainly for development/debugging.

## ğŸ” Security

Authentication is **optional by design.**

### Example header:

Authorization: Bearer YOUR_API_KEY

## ğŸ”Š Voice (Optional)

### Speech-to-Text

- Whisper (default)
- Vosk (offline fallback)

### Text-to-Speech

- XTTS (disabled by default)
- Outputs .wav files

## ğŸ§  Architecture
```plaintext
Client (API / CLI)
        |
        v
     FastAPI
        |
        v
   VeraEngine
        |
        +--> Memory (Vector Store)
        |
        +--> External RAG
        |
        v
      LLM (Ollama)
```

## ğŸ—„ï¸ Database
Schema defined in schema.sql.

## â¤ï¸ Credits
Built by Hoang Nguyen The